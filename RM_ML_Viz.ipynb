{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "mlenv",
   "display_name": "mlenv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, model_selection,tree, linear_model, neighbors, naive_bayes, ensemble \n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from path import Path\n"
   ]
  },
  {
   "source": [
    "## Visualizing the data and checking for correlations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(200, 7)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        State    Year   total_pop  Uninsured_%  PC_Income      GDP     Flu_%\n",
       "0     Alabama  2016.0   4863525.0          9.1    39536.0   191523  0.237400\n",
       "1      Alaska  2016.0    741456.0         14.0    56302.0    53289  0.143367\n",
       "2     Arizona  2016.0   6941072.0         10.0    40801.0   291259  0.322227\n",
       "3    Arkansas  2016.0   2989918.0          7.9    40385.0   113490  0.096424\n",
       "4  California  2016.0  39167117.0          7.3    58048.0  2519133  0.112745"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>Year</th>\n      <th>total_pop</th>\n      <th>Uninsured_%</th>\n      <th>PC_Income</th>\n      <th>GDP</th>\n      <th>Flu_%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>2016.0</td>\n      <td>4863525.0</td>\n      <td>9.1</td>\n      <td>39536.0</td>\n      <td>191523</td>\n      <td>0.237400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alaska</td>\n      <td>2016.0</td>\n      <td>741456.0</td>\n      <td>14.0</td>\n      <td>56302.0</td>\n      <td>53289</td>\n      <td>0.143367</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arizona</td>\n      <td>2016.0</td>\n      <td>6941072.0</td>\n      <td>10.0</td>\n      <td>40801.0</td>\n      <td>291259</td>\n      <td>0.322227</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arkansas</td>\n      <td>2016.0</td>\n      <td>2989918.0</td>\n      <td>7.9</td>\n      <td>40385.0</td>\n      <td>113490</td>\n      <td>0.096424</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>California</td>\n      <td>2016.0</td>\n      <td>39167117.0</td>\n      <td>7.3</td>\n      <td>58048.0</td>\n      <td>2519133</td>\n      <td>0.112745</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "# Load the viral_data.csv dataset.\n",
    "filepath = Path('viral_data.csv')\n",
    "viral_df = pd.read_csv(filepath, index_col=0)\n",
    "print(viral_df.shape)\n",
    "viral_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "viral_list = viral_df.dtypes[viral_df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   State_Alabama  State_Alaska  State_Arizona  State_Arkansas  \\\n",
       "0            1.0           0.0            0.0             0.0   \n",
       "1            0.0           1.0            0.0             0.0   \n",
       "2            0.0           0.0            1.0             0.0   \n",
       "3            0.0           0.0            0.0             1.0   \n",
       "4            0.0           0.0            0.0             0.0   \n",
       "\n",
       "   State_California  State_Colorado  State_Connecticut  State_Delaware  \\\n",
       "0               0.0             0.0                0.0             0.0   \n",
       "1               0.0             0.0                0.0             0.0   \n",
       "2               0.0             0.0                0.0             0.0   \n",
       "3               0.0             0.0                0.0             0.0   \n",
       "4               1.0             0.0                0.0             0.0   \n",
       "\n",
       "   State_Florida  State_Georgia  ...  State_South Dakota  State_Tennessee  \\\n",
       "0            0.0            0.0  ...                 0.0              0.0   \n",
       "1            0.0            0.0  ...                 0.0              0.0   \n",
       "2            0.0            0.0  ...                 0.0              0.0   \n",
       "3            0.0            0.0  ...                 0.0              0.0   \n",
       "4            0.0            0.0  ...                 0.0              0.0   \n",
       "\n",
       "   State_Texas  State_Utah  State_Vermont  State_Virginia  State_Washington  \\\n",
       "0          0.0         0.0            0.0             0.0               0.0   \n",
       "1          0.0         0.0            0.0             0.0               0.0   \n",
       "2          0.0         0.0            0.0             0.0               0.0   \n",
       "3          0.0         0.0            0.0             0.0               0.0   \n",
       "4          0.0         0.0            0.0             0.0               0.0   \n",
       "\n",
       "   State_West Virginia  State_Wisconsin  State_Wyoming  \n",
       "0                  0.0              0.0            0.0  \n",
       "1                  0.0              0.0            0.0  \n",
       "2                  0.0              0.0            0.0  \n",
       "3                  0.0              0.0            0.0  \n",
       "4                  0.0              0.0            0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State_Alabama</th>\n      <th>State_Alaska</th>\n      <th>State_Arizona</th>\n      <th>State_Arkansas</th>\n      <th>State_California</th>\n      <th>State_Colorado</th>\n      <th>State_Connecticut</th>\n      <th>State_Delaware</th>\n      <th>State_Florida</th>\n      <th>State_Georgia</th>\n      <th>...</th>\n      <th>State_South Dakota</th>\n      <th>State_Tennessee</th>\n      <th>State_Texas</th>\n      <th>State_Utah</th>\n      <th>State_Vermont</th>\n      <th>State_Virginia</th>\n      <th>State_Washington</th>\n      <th>State_West Virginia</th>\n      <th>State_Wisconsin</th>\n      <th>State_Wyoming</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(viral_df[viral_list]))\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(viral_list)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(200, 56)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Year   total_pop  Uninsured_%  PC_Income      GDP     Flu_%  \\\n",
       "0  2016.0   4863525.0          9.1    39536.0   191523  0.237400   \n",
       "1  2016.0    741456.0         14.0    56302.0    53289  0.143367   \n",
       "2  2016.0   6941072.0         10.0    40801.0   291259  0.322227   \n",
       "3  2016.0   2989918.0          7.9    40385.0   113490  0.096424   \n",
       "4  2016.0  39167117.0          7.3    58048.0  2519133  0.112745   \n",
       "\n",
       "   State_Alabama  State_Alaska  State_Arizona  State_Arkansas  ...  \\\n",
       "0            1.0           0.0            0.0             0.0  ...   \n",
       "1            0.0           1.0            0.0             0.0  ...   \n",
       "2            0.0           0.0            1.0             0.0  ...   \n",
       "3            0.0           0.0            0.0             1.0  ...   \n",
       "4            0.0           0.0            0.0             0.0  ...   \n",
       "\n",
       "   State_South Dakota  State_Tennessee  State_Texas  State_Utah  \\\n",
       "0                 0.0              0.0          0.0         0.0   \n",
       "1                 0.0              0.0          0.0         0.0   \n",
       "2                 0.0              0.0          0.0         0.0   \n",
       "3                 0.0              0.0          0.0         0.0   \n",
       "4                 0.0              0.0          0.0         0.0   \n",
       "\n",
       "   State_Vermont  State_Virginia  State_Washington  State_West Virginia  \\\n",
       "0            0.0             0.0               0.0                  0.0   \n",
       "1            0.0             0.0               0.0                  0.0   \n",
       "2            0.0             0.0               0.0                  0.0   \n",
       "3            0.0             0.0               0.0                  0.0   \n",
       "4            0.0             0.0               0.0                  0.0   \n",
       "\n",
       "   State_Wisconsin  State_Wyoming  \n",
       "0              0.0            0.0  \n",
       "1              0.0            0.0  \n",
       "2              0.0            0.0  \n",
       "3              0.0            0.0  \n",
       "4              0.0            0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>total_pop</th>\n      <th>Uninsured_%</th>\n      <th>PC_Income</th>\n      <th>GDP</th>\n      <th>Flu_%</th>\n      <th>State_Alabama</th>\n      <th>State_Alaska</th>\n      <th>State_Arizona</th>\n      <th>State_Arkansas</th>\n      <th>...</th>\n      <th>State_South Dakota</th>\n      <th>State_Tennessee</th>\n      <th>State_Texas</th>\n      <th>State_Utah</th>\n      <th>State_Vermont</th>\n      <th>State_Virginia</th>\n      <th>State_Washington</th>\n      <th>State_West Virginia</th>\n      <th>State_Wisconsin</th>\n      <th>State_Wyoming</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016.0</td>\n      <td>4863525.0</td>\n      <td>9.1</td>\n      <td>39536.0</td>\n      <td>191523</td>\n      <td>0.237400</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016.0</td>\n      <td>741456.0</td>\n      <td>14.0</td>\n      <td>56302.0</td>\n      <td>53289</td>\n      <td>0.143367</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016.0</td>\n      <td>6941072.0</td>\n      <td>10.0</td>\n      <td>40801.0</td>\n      <td>291259</td>\n      <td>0.322227</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016.0</td>\n      <td>2989918.0</td>\n      <td>7.9</td>\n      <td>40385.0</td>\n      <td>113490</td>\n      <td>0.096424</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016.0</td>\n      <td>39167117.0</td>\n      <td>7.3</td>\n      <td>58048.0</td>\n      <td>2519133</td>\n      <td>0.112745</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 56 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "viral_df = viral_df.merge(encode_df,left_index=True, right_index=True)\n",
    "viral_df = viral_df.drop(viral_list,1)\n",
    "print(viral_df.shape)\n",
    "viral_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Year   total_pop  Uninsured_%  PC_Income      GDP     Flu_%  \\\n",
       "0  2016.0   4863525.0          9.1    39536.0   191523  0.237400   \n",
       "1  2016.0    741456.0         14.0    56302.0    53289  0.143367   \n",
       "2  2016.0   6941072.0         10.0    40801.0   291259  0.322227   \n",
       "3  2016.0   2989918.0          7.9    40385.0   113490  0.096424   \n",
       "4  2016.0  39167117.0          7.3    58048.0  2519133  0.112745   \n",
       "\n",
       "   State_Alabama  State_Alaska  State_Arizona  State_Arkansas  ...  \\\n",
       "0            1.0           0.0            0.0             0.0  ...   \n",
       "1            0.0           1.0            0.0             0.0  ...   \n",
       "2            0.0           0.0            1.0             0.0  ...   \n",
       "3            0.0           0.0            0.0             1.0  ...   \n",
       "4            0.0           0.0            0.0             0.0  ...   \n",
       "\n",
       "   State_South Dakota  State_Tennessee  State_Texas  State_Utah  \\\n",
       "0                 0.0              0.0          0.0         0.0   \n",
       "1                 0.0              0.0          0.0         0.0   \n",
       "2                 0.0              0.0          0.0         0.0   \n",
       "3                 0.0              0.0          0.0         0.0   \n",
       "4                 0.0              0.0          0.0         0.0   \n",
       "\n",
       "   State_Vermont  State_Virginia  State_Washington  State_West Virginia  \\\n",
       "0            0.0             0.0               0.0                  0.0   \n",
       "1            0.0             0.0               0.0                  0.0   \n",
       "2            0.0             0.0               0.0                  0.0   \n",
       "3            0.0             0.0               0.0                  0.0   \n",
       "4            0.0             0.0               0.0                  0.0   \n",
       "\n",
       "   State_Wisconsin  State_Wyoming  \n",
       "0              0.0            0.0  \n",
       "1              0.0            0.0  \n",
       "2              0.0            0.0  \n",
       "3              0.0            0.0  \n",
       "4              0.0            0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>total_pop</th>\n      <th>Uninsured_%</th>\n      <th>PC_Income</th>\n      <th>GDP</th>\n      <th>Flu_%</th>\n      <th>State_Alabama</th>\n      <th>State_Alaska</th>\n      <th>State_Arizona</th>\n      <th>State_Arkansas</th>\n      <th>...</th>\n      <th>State_South Dakota</th>\n      <th>State_Tennessee</th>\n      <th>State_Texas</th>\n      <th>State_Utah</th>\n      <th>State_Vermont</th>\n      <th>State_Virginia</th>\n      <th>State_Washington</th>\n      <th>State_West Virginia</th>\n      <th>State_Wisconsin</th>\n      <th>State_Wyoming</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016.0</td>\n      <td>4863525.0</td>\n      <td>9.1</td>\n      <td>39536.0</td>\n      <td>191523</td>\n      <td>0.237400</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016.0</td>\n      <td>741456.0</td>\n      <td>14.0</td>\n      <td>56302.0</td>\n      <td>53289</td>\n      <td>0.143367</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016.0</td>\n      <td>6941072.0</td>\n      <td>10.0</td>\n      <td>40801.0</td>\n      <td>291259</td>\n      <td>0.322227</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016.0</td>\n      <td>2989918.0</td>\n      <td>7.9</td>\n      <td>40385.0</td>\n      <td>113490</td>\n      <td>0.096424</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016.0</td>\n      <td>39167117.0</td>\n      <td>7.3</td>\n      <td>58048.0</td>\n      <td>2519133</td>\n      <td>0.112745</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 56 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 172
    }
   ],
   "source": [
    "viral_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove flu_% target from features data\n",
    "y = np.array(viral_df['Flu_%'])\n",
    "X = viral_df.drop('Flu_%', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Features Shape: (160, 55)\nTesting Features Shape: (40, 55)\nTraining Labels Shape: (160,)\nTesting Labels Shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "# Check dat for correctness\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.95212926, 0.12035331, 0.57534639, 0.33380226, 0.1480135 ,\n",
       "       0.36635478, 0.10194584, 0.36098577, 0.35723435, 0.90167344,\n",
       "       0.23871651, 0.33913137, 0.57195798, 0.10854649, 0.50976398,\n",
       "       0.4537174 , 0.15961398, 0.34670707, 0.15942993, 0.15945133,\n",
       "       0.21941737, 0.22627333, 0.18477445, 0.41146122, 0.20376258,\n",
       "       0.1427818 , 0.09878894, 1.44865404, 0.4071206 , 0.22738401,\n",
       "       0.58181765, 0.09688865, 0.19631073, 0.24094772, 0.62535958,\n",
       "       0.21220535, 0.3053917 , 0.20514075, 0.20070386, 0.24197899])"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.22031026433195453"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "# Claculating the root mean square\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = y_test\n",
    "y_pred = predictions\n",
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7063831256478982"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "# Calculate the r-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestRegressor(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.21790218381740814"
      ]
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "# Calculating the root mean square\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = y_test\n",
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7127667491037964"
      ]
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "# Calculating the root square\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}